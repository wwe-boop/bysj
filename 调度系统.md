# 毕业论文创新方案：基于深度强化学习准入控制的LEO卫星网络QoE管理系统

## 1. 项目概述

本项目在《DSROQ》论文的基础上进行扩展和创新。原DSROQ框架解决了已有流量的联合路由、带宽分配和调度问题，以最大化全网用户的QoE。然而，它并未考虑在网络资源紧张时，是否应该接受新的流量请求。无限制地接受新流量可能导致网络拥塞，反而降低所有用户的体验。

**本项目旨在为DSROQ框架设计并实现一个智能“守门员”——基于深度强化学习（DRL）的动态准入控制模块。** 该模块将在接受一个新流量请求之前，评估其对整个网络QoE的潜在影响，从而做出最优的“接受”或“拒绝”决策，以实现全局、长期的QoE最大化。

## 2. 核心创新点

1.  **分层决策框架**：构建一个“准入-分配”分层决策框架。上层由DRL Agent负责宏观的准入控制，下层由DSROQ负责微观的资源分配（路由、带宽、调度）。
2.  **DRL赋能网络状态评估**：利用DRL强大的非线性拟合能力，让Agent从复杂的网络状态中学习到一个最优的准入策略，这比基于规则或固定阈值的传统方法更智能、更自适应。
3.  **QoE驱动的奖励机制**：为DRL Agent设计一个与最终用户体验（QoE）直接挂钩的奖励函数，确保准入决策的目标与网络运营的最终目标（最大化用户满意度）保持一致。

## 3. 系统架构设计

本系统将包含一个后端仿真核心和一个前端可视化界面，通过API连接。

* **后端（仿真核心）**：
    * **环境模块**：基于`SimPy`和`Skyfield`搭建的LEO卫星网络仿真环境。
    * **准入控制模块**：基于`PyTorch`和`Stable-Baselines3`实现的DRL Agent。
    * **资源分配模块**：原DSROQ的核心算法（MCTS路由+李雅普诺夫调度）实现。
    * **数据记录模块**：负责记录仿真过程中的关键性能指标（KPIs）。
* **前端（可视化界面）**：
    * 基于`Vue.js`/`React`构建，使用`CesiumJS`进行3D星座和网络拓扑可视化，`ECharts`进行数据图表展示。
* **API接口**：
    * 基于`Flask`实现，负责前后端通信，例如启动仿真、传递参数、返回结果等。

## 4. 算法设计与实现 (核心提示词)

### 模块一：DRL准入控制Agent (新增模块)

此模块是整个系统的“智能守门员”。当一个新的 aggregated flow $f_{new}$ 请求进入网络时，DRL Agent将根据当前网络状态决定接受或拒绝。

* **马尔可夫决策过程 (MDP) 定义**:
    * **状态 (State, S)**：Agent观察到的网络全局信息，必须包含足够的信息来做出判断。可以定义为一个向量：
        ```
        S = [
             // 全局网络状态
             U_avg, U_max,       // 平均/最大链路利用率
             N_ef, N_af, N_be,   // EF, AF, BE三类流量的当前数量
             QoE_avg_ef, QoE_avg_af, QoE_avg_be, // 各类流量的平均QoE分数

             // 新流量请求的信息
             Type_new,           // 新流量的类型 (EF/AF/BE)
             B_req_min, B_req_max, // 新流量的最小/最大带宽需求 (τ_f^min, τ_f^max)
             L_req_max            // 新流量的最大延迟要求 (δ_f^max)
            ]
        ```
    * **动作 (Action, A)**：Agent的决策空间非常简单，是一个离散动作。
        ```
        A = {0: 拒绝 (Reject), 1: 接受 (Accept)}
        ```
    * **奖励 (Reward, R)**：这是设计的核心。奖励函数引导Agent学习目标。在执行一个动作后（例如，在时间点`t`接受了一个新流量），我们在下一个时间窗口结束时（`t+T`）计算奖励。
        ```
        // 伪代码
        function calculate_reward(action, state_before, state_after):
            // 获取动作执行后的全网平均QoE分数
            QoE_global_after = state_after.weighted_sum_QoE

            if action == ACCEPT:
                // 如果接受流量导致了网络QoE下降，给予负反馈
                // 如果QoE提升或维持，给予正反馈
                reward = QoE_global_after - state_before.weighted_sum_QoE
            
            if action == REJECT:
                // 拒绝是一个保守操作，给予一个小的、固定的正奖励或零奖励
                // 避免Agent为了寻求安稳而无脑拒绝所有请求
                reward = 0.1 

            // 可选：增加对EF类流量QoS违规的巨大惩罚
            if state_after.ef_qos_violation_rate > threshold:
                reward = reward - 10.0 // 巨大惩罚项
            
            return reward
        ```
    * **算法选择**:
        * 推荐使用**PPO (Proximal Policy Optimization)**算法，它在离散和连续动作空间中都表现稳健，是目前的主流选择。
        * **实现库**: `Stable-Baselines3` (基于PyTorch)，它封装了PPO等多种算法，可以让你专注于MDP的设计。

### 模块二：DSROQ核心资源分配 (原论文模块)

此模块在DRL Agent决定“接受”一个新流量后被触发。

* **MCTS路由与带宽分配**:
    * 当一个新流量`f_new`被准入后，它将被加入到待处理的流量集合 `F` 中。
    * MCTS算法将为**包括`f_new`在内的所有流量**重新进行一次联合的路由和带宽分配决策。
    * **输入**: 全部的流量集合`F`，当前的网络拓扑。
    * **输出**: 为每个流量`f`分配的路由`r_f`和带宽`B_f`。
* **李雅普诺夫调度**:
    * 在MCTS分配完路由和带宽后，每个卫星节点上的调度器将按照论文中的公式(16)进行逐个时间片的调度。
    * 这是网络运行的微观执行层面。

### 模块三：端到端仿真流程

1.  **初始化**：加载星座拓扑，初始化网络环境，实例化DRL Agent和DSROQ模块。
2.  **流量生成**：根据泊松分布随机生成新的流量请求`f_new`。
3.  **准入决策 (DRL)**：
    a. 从仿真环境中提取当前的网络状态`S`。
    b. 将`S`输入到DRL Agent的神经网络中，Agent输出动作`A` (接受/拒绝)。
    c. 执行动作`A`。
4.  **资源分配 (DSROQ)**：
    a. 如果`A`是“接受”，则将`f_new`加入网络。
    b. 调用MCTS模块为全网流量进行路由和带宽重分配。
5.  **网络运行与调度**：
    a. 启动`SimPy`离散事件仿真，持续一个时间窗口`T`。
    b. 在此期间，所有节点上的调度器按照李雅普诺夫规则工作。
6.  **评估与学习**：
    a. 在时间窗口`T`结束后，计算全网的QoE等性能指标，形成新的网络状态`S_next`。
    b. 根据奖励函数`R`计算本次决策的奖励。
    c. 将`(S, A, R, S_next)`这个经验元组存入DRL Agent的经验池中，用于训练和更新其策略网络。
7.  **循环**：返回第2步，不断生成新流量，循环此过程。

## 5. 技术栈总结

| 类别             | 技术/库                               | 用途                               |
| ---------------- | ------------------------------------- | ---------------------------------- |
| **后端仿真** | Python 3.8+                           | 主要开发语言                       |
|                  | SimPy                                 | 离散事件仿真核心框架               |
|                  | Skyfield                              | 卫星星座轨道与拓扑计算             |
|                  | NetworkX                              | 网络图结构表示与操作               |
|                  | NumPy, Pandas                         | 科学计算与数据分析                 |
| **机器学习** | PyTorch                               | 深度学习框架 (DRL Agent底层)       |
|                  | Stable-Baselines3                     | 预封装的强化学习算法库 (PPO)       |
| **前端可视化** | Vue.js / React                        | 前端开发框架                       |
|                  | CesiumJS / Three.js                   | 3D地球与卫星星座可视化             |
|                  | ECharts / D3.js                       | 2D数据图表绘制                     |
| **Web服务器/API**| Flask                                 | 轻量级Web框架，用于构建API接口     |